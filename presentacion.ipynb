{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# FASE DE EXPLORACIÓN Y ANÁLISIS DE LOS DATOS",
   "id": "a314633af6e3345a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.) IMPORTACIÓN DE LIBRERIAS",
   "id": "90d40464d8fb0fe8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T15:40:04.669394Z",
     "start_time": "2025-11-03T15:40:04.666331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ],
   "id": "7100607b5cad1845",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.) Configuración Inicial y Funciones de Utilidad",
   "id": "ed68f76082e0e7ff"
  },
  {
   "cell_type": "code",
   "id": "e68a6eb4187a401e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T15:40:04.679852Z",
     "start_time": "2025-11-03T15:40:04.674445Z"
    }
   },
   "source": [
    "# Configuración inicial y funciones auxiliares\n",
    "def normalizar_texto(texto):\n",
    "    \"\"\"Normaliza texto para comparaciones más robustas\"\"\"\n",
    "    if pd.isna(texto):\n",
    "        return \"\"\n",
    "    return str(texto).lower().strip()\n",
    "\n",
    "def cargar_y_combinar_datos(archivos):\n",
    "    \"\"\"Carga y combina todos los archivos CSV en un solo DataFrame\"\"\"\n",
    "    dfs = []\n",
    "    for archivo in archivos:\n",
    "        if os.path.exists(archivo):\n",
    "            encodings = [\"latin-1\", \"ISO-8859-1\", \"utf-8\"]\n",
    "            separadores = [\";\", \",\"]\n",
    "\n",
    "            cargado = False\n",
    "            for encoding in encodings:\n",
    "                if cargado:\n",
    "                    break\n",
    "                for sep in separadores:\n",
    "                    try:\n",
    "                        df = pd.read_csv(archivo, encoding=encoding, sep=sep)\n",
    "                        if len(df.columns) > 1:\n",
    "                            dfs.append(df)\n",
    "                            print(f\"✓ {archivo} cargado con encoding {encoding} y separador '{sep}'\")\n",
    "                            cargado = True\n",
    "                            break\n",
    "                    except (UnicodeDecodeError, pd.errors.ParserError):\n",
    "                        continue\n",
    "            if not cargado:\n",
    "                print(f\"✗ No se pudo cargar {archivo} con ninguna combinación de encoding/separador\")\n",
    "        else:\n",
    "            print(f\"Advertencia: No se encontró el archivo {archivo}\")\n",
    "\n",
    "    if not dfs:\n",
    "        raise Exception(\"No se pudieron cargar ninguno de los archivos\")\n",
    "\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "##Definimos funciones básicas para normalizar texto y cargar múltiples archivos CSV con diferentes codificaciones y separadores, manejando posibles errores de lectura.\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.)  Identificación Automática de Columnas",
   "id": "6617c932f21c21ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T15:40:04.689890Z",
     "start_time": "2025-11-03T15:40:04.684872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Función para identificar automáticamente las columnas relevantes\n",
    "def identificar_columnas(df):\n",
    "    \"\"\"Identifica automáticamente los nombres de las columnas clave\"\"\"\n",
    "    columnas = df.columns.tolist()\n",
    "    print(\"Columnas disponibles:\", columnas)\n",
    "\n",
    "    # Buscar posibles nombres para documento\n",
    "    doc_posibles = [\"Documento\", \"documento\", \"DOCUMENTO\", \"NumeroDocumento\", \"NroDocumento\"]\n",
    "    for doc in doc_posibles:\n",
    "        if doc in columnas:\n",
    "            doc_col = doc\n",
    "            break\n",
    "    else:\n",
    "        for col in columnas:\n",
    "            if \"doc\" in col.lower() or \"id\" in col.lower() or \"numero\" in col.lower():\n",
    "                doc_col = col\n",
    "                break\n",
    "        else:\n",
    "            doc_col = columnas[1] if len(columnas) > 1 else columnas[0]\n",
    "\n",
    "    # Buscar posibles nombres para medicamento\n",
    "    med_posibles = [\"Medicamento\", \"medicamento\", \"MEDICAMENTO\", \"MedicamentoNombre\", \"NombreMedicamento\"]\n",
    "    for med in med_posibles:\n",
    "        if med in columnas:\n",
    "            med_col = med\n",
    "            break\n",
    "    else:\n",
    "        for col in columnas:\n",
    "            if \"medic\" in col.lower() or \"drug\" in col.lower() or \"farma\" in col.lower():\n",
    "                med_col = col\n",
    "                break\n",
    "        else:\n",
    "            med_col = columnas[4] if len(columnas) > 4 else columnas[2]\n",
    "\n",
    "    print(f\"Usando columna para documento: {doc_col}\")\n",
    "    print(f\"Usando columna para medicamento: {med_col}\")\n",
    "\n",
    "    return doc_col, med_col\n",
    "\n",
    "## Esta función identifica automáticamente las columnas de documento y medicamento en el dataset, lo que hace el script más robusto frente a variaciones en los nombres de columnas."
   ],
   "id": "1f2ff42ce633f700",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4.)  Detección de Medicamentos de Interés",
   "id": "38f7255113a71ea3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T15:40:04.698903Z",
     "start_time": "2025-11-03T15:40:04.693899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Funciones para detectar medicamentos de los 7 grupos de interés\n",
    "def buscar_medicamentos_exactos(texto_medicamento):\n",
    "    \"\"\"Busca EXACTAMENTE los medicamentos de interés en el texto, evitando falsos positivos\"\"\"\n",
    "    texto = normalizar_texto(texto_medicamento)\n",
    "\n",
    "    # Diccionario de medicamentos con sus nombres EXACTOS y grupos\n",
    "    medicamentos_exactos = {\n",
    "        # GRUPO ESPECIAL\n",
    "        \"metoprolol\": \"GE_metoprolol\",\n",
    "        \"propranolol\": \"GE_metoprolol\",\n",
    "        \"propanolol\": \"GE_metoprolol\",\n",
    "        \"hidroclorotiazida\": \"GE_hidroclorotiazida\",\n",
    "        # ARA II\n",
    "        \"irbesartan\": \"ARA_II\",\n",
    "        \"valsartan\": \"ARA_II\",\n",
    "        \"olmesartan\": \"ARA_II\",\n",
    "        \"telmisartan\": \"ARA_II\",\n",
    "        \"losartan\": \"ARA_II\",\n",
    "        # IECA\n",
    "        \"enalapril\": \"IECA\",\n",
    "        \"captopril\": \"IECA\",\n",
    "        \"perindopril\": \"IECA\",\n",
    "        # Calcioantagonistas\n",
    "        \"amlodipino\": \"Calcioantagonistas\",\n",
    "        \"nifedipino\": \"Calcioantagonistas\",\n",
    "        \"verapamilo\": \"Calcioantagonistas\",\n",
    "        # Otros diuréticos\n",
    "        \"espironolactona\": \"Otros_diuréticos\",\n",
    "        \"furosemida\": \"Otros_diuréticos\",\n",
    "        \"indapamida\": \"Otros_diuréticos\",\n",
    "        \"clortalidona\": \"Otros_diuréticos\",\n",
    "        # Otros Beta-Bloqueadores\n",
    "        \"bisoprolol\": \"Otros_Beta_Bloqueadores\",\n",
    "        \"carvedilol\": \"Otros_Beta_Bloqueadores\",\n",
    "        \"nebivolol\": \"Otros_Beta_Bloqueadores\",\n",
    "        # Otros antihipertensivos\n",
    "        \"minoxidil\": \"Otros_antihipertensivos\",\n",
    "        \"prazosina\": \"Otros_antihipertensivos\",\n",
    "        \"clonidina\": \"Otros_antihipertensivos\",\n",
    "    }\n",
    "\n",
    "    grupos_encontrados = set()\n",
    "\n",
    "    # Buscar cada medicamento EXACTAMENTE en el texto\n",
    "    for medicamento, grupo in medicamentos_exactos.items():\n",
    "        # Usar regex para buscar la palabra completa, evitando subcadenas\n",
    "        if re.search(r\"\\b\" + re.escape(medicamento) + r\"\\b\", texto):\n",
    "            grupos_encontrados.add(grupo)\n",
    "\n",
    "    return list(grupos_encontrados)\n",
    "\n",
    "## Explicación: Define la lógica para detectar exactamente los medicamentos de los 7 grupos de interés usando búsqueda por palabras completas para evitar falsos positivos."
   ],
   "id": "bc5bb3a84cb9740e",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5.) Detección Inteligente de Medicamentos \"X\"",
   "id": "f99d9dc4376089eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T15:40:04.710179Z",
     "start_time": "2025-11-03T15:40:04.703181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Función para detectar medicamentos adicionales (X) de forma inteligente\n",
    "def tiene_medicamento_x(texto_medicamento, grupos_encontrados):\n",
    "    \"\"\"Determina si hay medicamentos X adicionales de manera más inteligente\"\"\"\n",
    "    texto = normalizar_texto(texto_medicamento)\n",
    "\n",
    "    # Lista de palabras comunes en descripciones de medicamentos (NO son medicamentos X)\n",
    "    palabras_no_x = {\n",
    "        \"mg\", \"mcg\", \"g\", \"ml\", \"l\", \"cc\", \"tableta\", \"tabletas\", \"comprimido\", \"comprimidos\",\n",
    "        \"capsula\", \"capsulas\", \"cápsula\", \"cápsulas\", \"gragea\", \"grageas\", \"inyección\", \"ampolla\",\n",
    "        \"frasco\", \"sobre\", \"suspension\", \"suspensión\", \"jarabe\", \"crema\", \"pomada\", \"supositorio\",\n",
    "        \"spray\", \"inhalador\", \"parche\", \"ungüento\", \"oral\", \"intramuscular\", \"intravenoso\",\n",
    "        \"subcutaneo\", \"subcutáneo\", \"topico\", \"tópico\", \"rectal\", \"vaginal\", \"oftalmico\", \"oftálmico\",\n",
    "        \"otico\", \"ótico\", \"nasal\", \"cada\", \"horas\", \"día\", \"dias\", \"semana\", \"semanas\", \"mes\", \"meses\",\n",
    "        \"año\", \"años\", \"dosis\", \"frecuencia\", \"tratamiento\", \"tomar\", \"aplicar\", \"uso\", \"adultos\",\n",
    "        \"niños\", \"pacientes\", \"administrar\", \"via\", \"cad\", \"diaria\", \"semanal\", \"mensual\", \"anual\",\n",
    "        \"continuo\", \"alternos\", \"mg\", \"mcg\", \"g\", \"ml\", \"l\", \"cc\", \"ui\", \"unidad\", \"unidades\",\n",
    "        \"por\", \"con\", \"sin\", \"de\", \"la\", \"el\", \"y\", \"o\", \"para\", \"entre\", \"hasta\", \"desde\", \"sobre\",\n",
    "        \"bajo\", \"tras\", \"durante\", \"antes\", \"después\", \"al\", \"del\", \"se\", \"es\", \"en\", \"a\", \"u\", \"un\",\n",
    "        \"una\", \"unos\", \"unas\", \"uno\", \"dos\", \"tres\", \"cuatro\", \"cinco\", \"seis\", \"siete\", \"ocho\", \"nueve\",\n",
    "        \"diez\", \"cien\", \"mil\", \"medio\", \"media\", \"cuarto\", \"cuarta\", \"primera\", \"segunda\", \"tercera\",\n",
    "        \"tartrato\", \"bloqueadores\", \"antihipertensivos\", \"diuréticos\", \"bloqueador\", \"antihipertensivo\",\n",
    "        \"diurético\", \"calcioantagonistas\", \"calcioantagonista\", \"hidroclorotiazida\", \"clorhidrato\",\n",
    "        \"maleato\", \"succinato\", \"besilato\", \"valsartan\", \"irbesartan\", \"telmisartan\", \"olmesartan\",\n",
    "        \"losartan\", \"enalapril\", \"captopril\", \"perindopril\", \"amlodipino\", \"nifedipino\", \"verapamilo\",\n",
    "        \"espironolactona\", \"furosemida\", \"indapamida\", \"clortalidona\", \"bisoprolol\", \"carvedilol\",\n",
    "        \"nebivolol\", \"minoxidil\", \"prazosina\", \"clonidina\", \"metoprolol\", \"propranolol\", \"propanolol\",\n",
    "    }\n",
    "\n",
    "    # Remover los medicamentos encontrados\n",
    "    texto_limpio = texto\n",
    "    for grupo in grupos_encontrados:\n",
    "        medicamentos_grupo = {\n",
    "            \"GE_metoprolol\": [\"metoprolol\", \"propranolol\", \"propanolol\"],\n",
    "            \"GE_hidroclorotiazida\": [\"hidroclorotiazida\"],\n",
    "            \"ARA_II\": [\"irbesartan\", \"valsartan\", \"olmesartan\", \"telmisartan\", \"losartan\"],\n",
    "            \"IECA\": [\"enalapril\", \"captopril\", \"perindopril\"],\n",
    "            \"Calcioantagonistas\": [\"amlodipino\", \"nifedipino\", \"verapamilo\"],\n",
    "            \"Otros_diuréticos\": [\"espironolactona\", \"furosemida\", \"indapamida\", \"clortalidona\"],\n",
    "            \"Otros_Beta_Bloqueadores\": [\"bisoprolol\", \"carvedilol\", \"nebivolol\"],\n",
    "            \"Otros_antihipertensivos\": [\"minoxidil\", \"prazosina\", \"clonidina\"],\n",
    "        }\n",
    "\n",
    "        if grupo in medicamentos_grupo:\n",
    "            for med in medicamentos_grupo[grupo]:\n",
    "                texto_limpio = re.sub(r\"\\b\" + re.escape(med) + r\"\\b\", \"\", texto_limpio)\n",
    "\n",
    "    # Remover palabras no-X y números, buscar palabras de 4+ letras\n",
    "    palabras = re.findall(r\"[a-zA-Z]{4,}\", texto_limpio)  # Solo palabras de 4+ letras\n",
    "    palabras_filtradas = [p for p in palabras if p not in palabras_no_x]\n",
    "\n",
    "    # También verificar si hay signos de múltiples medicamentos (+, &, \"y\", \"con\")\n",
    "    tiene_multiples = bool(re.search(r\"\\+|\\&| y | con |/\\s*[a-zA-Z]\", texto))\n",
    "\n",
    "    return len(palabras_filtradas) > 0 or tiene_multiples\n",
    "\n",
    "## Explicación: Implementa la lógica inteligente para detectar medicamentos \"X\" (cualquier medicamento adicional), filtrando palabras comunes de dosis y formas farmacéuticas para evitar falsos positivos."
   ],
   "id": "8bea2091f901ca5",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6.) Sistema de Categorización por Registro",
   "id": "488cd8adcf17785e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T15:40:04.721666Z",
     "start_time": "2025-11-03T15:40:04.714363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## # Sistema completo de categorización por registro individual\n",
    "def determinar_categorizacion_por_registro(medicamento_str):\n",
    "    \"\"\"Determina la categorización INDIVIDUAL para CADA REGISTRO\"\"\"\n",
    "    # Buscar grupos de medicamentos EXACTOS\n",
    "    grupos = buscar_medicamentos_exactos(medicamento_str)\n",
    "\n",
    "    # Si no hay medicamentos de interés, no procesar\n",
    "    if not grupos:\n",
    "        return \"NO_APLICA\"\n",
    "\n",
    "    # Determinar si hay medicamento X\n",
    "    hay_x = tiene_medicamento_x(medicamento_str, grupos)\n",
    "\n",
    "    # Mapeo de nombres de grupos a nombres de categorización\n",
    "    mapeo_categorias = {\n",
    "        \"GE_metoprolol\": \"GE metoprolol\",\n",
    "        \"GE_hidroclorotiazida\": \"GE Hidroclorotiazida\",\n",
    "        \"ARA_II\": \"ARA II\",\n",
    "        \"IECA\": \"IECA\",\n",
    "        \"Calcioantagonistas\": \"Calcioantagonistas\",\n",
    "        \"Otros_diuréticos\": \"Otros diuréticos\",\n",
    "        \"Otros_Beta_Bloqueadores\": \"Otros Beta-Bloqueadores\",\n",
    "        \"Otros_antihipertensivos\": \"Otros Anti-Hipertensivos\",\n",
    "    }\n",
    "\n",
    "    # Convertir grupos internos a nombres de categoría\n",
    "    grupos_categoria = [mapeo_categorias[grupo] for grupo in grupos]\n",
    "\n",
    "    # REGLAS DE CATEGORIZACIÓN - POR REGISTRO INDIVIDUAL\n",
    "\n",
    "    # 1. Verificar presencia de Grupo Especial (GE)\n",
    "    tiene_ge_metoprolol = \"GE metoprolol\" in grupos_categoria\n",
    "    tiene_ge_hidro = \"GE Hidroclorotiazida\" in grupos_categoria\n",
    "\n",
    "    # Contar medicamentos de grupos no especiales en ESTE registro\n",
    "    grupos_no_especiales = [\n",
    "        g\n",
    "        for g in grupos_categoria\n",
    "        if g not in [\"GE metoprolol\", \"GE Hidroclorotiazida\"]\n",
    "    ]\n",
    "    total_grupos_no_especiales = len(grupos_no_especiales)\n",
    "\n",
    "    # Si hay Grupo Especial en este registro\n",
    "    if tiene_ge_metoprolol or tiene_ge_hidro:\n",
    "        # CASO 1: Solo metoprolol (sin hidro, sin otros grupos, sin X)\n",
    "        if (\n",
    "                tiene_ge_metoprolol\n",
    "                and not tiene_ge_hidro\n",
    "                and total_grupos_no_especiales == 0\n",
    "                and not hay_x\n",
    "        ):\n",
    "            return \"GE metoprolol univ\"\n",
    "\n",
    "        # CASO 2: Solo hidroclorotiazida (sin metoprolol, sin otros grupos, sin X)\n",
    "        elif (\n",
    "                not tiene_ge_metoprolol\n",
    "                and tiene_ge_hidro\n",
    "                and total_grupos_no_especiales == 0\n",
    "                and not hay_x\n",
    "        ):\n",
    "            return \"GE Hidroclorotiazida univ\"\n",
    "\n",
    "        # CASO 3: Metoprolol + hidroclorotiazida (sin otros grupos, sin X)\n",
    "        elif (\n",
    "                tiene_ge_metoprolol\n",
    "                and tiene_ge_hidro\n",
    "                and total_grupos_no_especiales == 0\n",
    "                and not hay_x\n",
    "        ):\n",
    "            return \"GE Hidro-Meto univ\"\n",
    "\n",
    "        # CASO 4: Metoprolol + X (CUALQUIER medicamento adicional)\n",
    "        elif tiene_ge_metoprolol and not tiene_ge_hidro and hay_x:\n",
    "            return \"GE Meto-X univ\"\n",
    "\n",
    "        # CASO 5: Hidroclorotiazida + X (CUALQUIER medicamento adicional)\n",
    "        elif not tiene_ge_metoprolol and tiene_ge_hidro and hay_x:\n",
    "            return \"GE Hidro-X univ\"\n",
    "\n",
    "        # CASO 6: Metoprolol + hidroclorotiazida + X (CUALQUIER medicamento adicional)\n",
    "        elif tiene_ge_metoprolol and tiene_ge_hidro and hay_x:\n",
    "            return \"GE Hidro-Meto 2\"\n",
    "\n",
    "        # CASO 7: Metoprolol + otros grupos (sin X)\n",
    "        elif (\n",
    "                tiene_ge_metoprolol\n",
    "                and not tiene_ge_hidro\n",
    "                and total_grupos_no_especiales > 0\n",
    "                and not hay_x\n",
    "        ):\n",
    "            otros_grupos_str = \" & \".join(grupos_no_especiales)\n",
    "            return f\"GE Meto & {otros_grupos_str} univ\"\n",
    "\n",
    "        # CASO 8: Hidroclorotiazida + otros grupos (sin X)\n",
    "        elif (\n",
    "                not tiene_ge_metoprolol\n",
    "                and tiene_ge_hidro\n",
    "                and total_grupos_no_especiales > 0\n",
    "                and not hay_x\n",
    "        ):\n",
    "            otros_grupos_str = \" & \".join(grupos_no_especiales)\n",
    "            return f\"GE Hidro & {otros_grupos_str} univ\"\n",
    "\n",
    "    # 2. Si no hay Grupo Especial, categorizar grupos no especiales\n",
    "    else:\n",
    "        if len(grupos_categoria) == 1:\n",
    "            return f\"{grupos_categoria[0]} univ\"\n",
    "        else:\n",
    "            # Múltiples grupos no especiales\n",
    "            return f\"{' & '.join(grupos_categoria)} univ\"\n",
    "\n",
    "    return \"Categorización no definida\"\n",
    "\n",
    "def es_registro_de_interes(medicamento_str):\n",
    "    \"\"\"Determina si un registro contiene al menos un medicamento de interés\"\"\"\n",
    "    grupos = buscar_medicamentos_exactos(medicamento_str)\n",
    "    return len(grupos) > 0\n",
    "\n",
    "\n",
    "\n",
    "## Implementa el sistema completo de categorización que aplica las reglas de negocio para asignar la etiqueta correcta a cada registro individualmente."
   ],
   "id": "b4aa00cbc6fef89d",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7.) Procesamiento Principal y Generación del CSV Final",
   "id": "16ad9d8a678719e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T15:40:04.729941Z",
     "start_time": "2025-11-03T15:40:04.726061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Procesamiento principal y generación del dataset final\n",
    "def procesar_csv_por_registro(df, doc_col, med_col):\n",
    "    \"\"\"Procesa CADA REGISTRO individualmente y genera el CSV de salida\"\"\"\n",
    "    registros_procesados = []\n",
    "\n",
    "    print(f\"Procesando {len(df)} registros individualmente...\")\n",
    "    registros_con_interes = 0\n",
    "\n",
    "    for indice, fila in df.iterrows():\n",
    "        medicamento = fila[med_col]\n",
    "\n",
    "        # SOLO procesar si el registro tiene medicamentos de interés\n",
    "        if es_registro_de_interes(medicamento):\n",
    "            registros_con_interes += 1\n",
    "\n",
    "            # Crear copia del registro\n",
    "            registro_procesado = fila.to_dict()\n",
    "\n",
    "            # Asignar categorización INDIVIDUAL para este registro\n",
    "            categoria = determinar_categorizacion_por_registro(medicamento)\n",
    "            registro_procesado[\"Categorización\"] = categoria\n",
    "\n",
    "            registros_procesados.append(registro_procesado)\n",
    "\n",
    "    print(f\"Registros con medicamentos de interés: {registros_con_interes}\")\n",
    "    return registros_procesados"
   ],
   "id": "f8a7478f1886beae",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 8.) Ejecución Completa del Pipeline",
   "id": "9a5108bda6c0b6be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-03T15:41:36.107231Z",
     "start_time": "2025-11-03T15:40:04.735947Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ejecución completa del pipeline de procesamiento\n",
    "def main():\n",
    "    \"\"\"Función principal\"\"\"\n",
    "    archivos = [\n",
    "        \"Antihipertensivos1.csv\",\n",
    "        \"Antihipertensivos2.csv\",\n",
    "        \"OtrosMedicamentos.csv\",\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        print(\"Cargando y combinando datos desde CSV...\")\n",
    "        df_completo = cargar_y_combinar_datos(archivos)\n",
    "\n",
    "        print(\"\\nIdentificando columnas...\")\n",
    "        doc_col, med_col = identificar_columnas(df_completo)\n",
    "\n",
    "        print(\"Procesando registros INDIVIDUALMENTE...\")\n",
    "        registros_finales = procesar_csv_por_registro(df_completo, doc_col, med_col)\n",
    "\n",
    "        # Crear DataFrame final\n",
    "        if registros_finales:\n",
    "            df_final = pd.DataFrame(registros_finales)\n",
    "\n",
    "            # Reordenar columnas para que 'Categorización' esté al final\n",
    "            if \"Categorización\" in df_final.columns:\n",
    "                columnas = [\n",
    "                               col for col in df_final.columns if col != \"Categorización\"\n",
    "                           ] + [\"Categorización\"]\n",
    "                df_final = df_final[columnas]\n",
    "\n",
    "            # Guardar el archivo final\n",
    "            archivo_salida = \"registros_clasificados_por_medicamento_final.csv\"\n",
    "            df_final.to_csv(archivo_salida, index=False, encoding=\"utf-8-sig\", sep=\";\")\n",
    "\n",
    "            print(f\"\\n=== PROCESO COMPLETADO CON ÉXITO ===\")\n",
    "            print(f\"Archivo generado: {archivo_salida}\")\n",
    "            print(f\"Total de registros procesados: {len(df_final)}\")\n",
    "\n",
    "            # Mostrar resumen de categorizaciones\n",
    "            print(f\"\\nResumen de categorizaciones POR REGISTRO:\")\n",
    "            categorias_count = df_final[\"Categorización\"].value_counts()\n",
    "            for categoria, count in categorias_count.items():\n",
    "                print(f\"  {categoria}: {count} registros\")\n",
    "\n",
    "            print(f\"\\nTotal de categorías únicas: {len(categorias_count)}\")\n",
    "\n",
    "        else:\n",
    "            print(\"No se encontraron registros con medicamentos de interés\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error durante la ejecución: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Ejecutar el proceso completo\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "## Función principal que orquesta todo el proceso: carga de datos, identificación de columnas, procesamiento individual y generación del CSV final con estadísticas del proceso."
   ],
   "id": "e3e0c503c1b42f16",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando y combinando datos desde CSV...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alejandro\\AppData\\Local\\Temp\\ipykernel_7924\\961491581.py:22: DtypeWarning: Columns (13,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(archivo, encoding=encoding, sep=sep)\n",
      "C:\\Users\\Alejandro\\AppData\\Local\\Temp\\ipykernel_7924\\961491581.py:22: DtypeWarning: Columns (13,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(archivo, encoding=encoding, sep=sep)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Antihipertensivos1.csv cargado con encoding latin-1 y separador ';'\n",
      "✓ Antihipertensivos2.csv cargado con encoding latin-1 y separador ';'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alejandro\\AppData\\Local\\Temp\\ipykernel_7924\\961491581.py:22: DtypeWarning: Columns (13,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(archivo, encoding=encoding, sep=sep)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ OtrosMedicamentos.csv cargado con encoding latin-1 y separador ';'\n",
      "\n",
      "Identificando columnas...\n",
      "Columnas disponibles: ['Secuencia', 'Documento', 'CodProced', 'Num_orden', 'Medicamento', 'Frecuencia', 'Dosis', 'Via', 'TTratamiento', 'Empresa', 'Cantidad', 'Item', 'Especialidad', 'NumProfe', 'MedicoOrdena', 'Nom1PAc', 'Nom2Pac', 'Apell1Pac', 'Apell2Pac', 'Fechnac', 'Sexo', 'Direcion', 'Tel', 'FechaOrden', 'CANTIDAD', 'Observaciones', 'Fecha_atencion', 'sede_id', 'lugar', 'num_formula', 'nombrepac', 'edad', 'telefono', 'sexo', 'direccion', 'empresa', 'dxppal', 'desdxppal']\n",
      "Usando columna para documento: Documento\n",
      "Usando columna para medicamento: Medicamento\n",
      "Procesando registros INDIVIDUALMENTE...\n",
      "Procesando 1020024 registros individualmente...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[32]\u001B[39m\u001B[32m, line 57\u001B[39m\n\u001B[32m     55\u001B[39m \u001B[38;5;66;03m# Ejecutar el proceso completo\u001B[39;00m\n\u001B[32m     56\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[34m__name__\u001B[39m == \u001B[33m\"\u001B[39m\u001B[33m__main__\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m---> \u001B[39m\u001B[32m57\u001B[39m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     59\u001B[39m \u001B[38;5;66;03m## Función principal que orquesta todo el proceso: carga de datos, identificación de columnas, procesamiento individual y generación del CSV final con estadísticas del proceso.\u001B[39;00m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[32]\u001B[39m\u001B[32m, line 18\u001B[39m, in \u001B[36mmain\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     15\u001B[39m doc_col, med_col = identificar_columnas(df_completo)\n\u001B[32m     17\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mProcesando registros INDIVIDUALMENTE...\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m registros_finales = \u001B[43mprocesar_csv_por_registro\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf_completo\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdoc_col\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmed_col\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     20\u001B[39m \u001B[38;5;66;03m# Crear DataFrame final\u001B[39;00m\n\u001B[32m     21\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m registros_finales:\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[31]\u001B[39m\u001B[32m, line 17\u001B[39m, in \u001B[36mprocesar_csv_por_registro\u001B[39m\u001B[34m(df, doc_col, med_col)\u001B[39m\n\u001B[32m     14\u001B[39m registros_con_interes += \u001B[32m1\u001B[39m\n\u001B[32m     16\u001B[39m \u001B[38;5;66;03m# Crear copia del registro\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m17\u001B[39m registro_procesado = \u001B[43mfila\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     19\u001B[39m \u001B[38;5;66;03m# Asignar categorización INDIVIDUAL para este registro\u001B[39;00m\n\u001B[32m     20\u001B[39m categoria = determinar_categorizacion_por_registro(medicamento)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001B[39m, in \u001B[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    327\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) > num_allow_args:\n\u001B[32m    328\u001B[39m     warnings.warn(\n\u001B[32m    329\u001B[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001B[32m    330\u001B[39m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[32m    331\u001B[39m         stacklevel=find_stack_level(),\n\u001B[32m    332\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m333\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:2077\u001B[39m, in \u001B[36mSeries.to_dict\u001B[39m\u001B[34m(self, into)\u001B[39m\n\u001B[32m   2074\u001B[39m into_c = com.standardize_mapping(into)\n\u001B[32m   2076\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_object_dtype(\u001B[38;5;28mself\u001B[39m.dtype) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m.dtype, ExtensionDtype):\n\u001B[32m-> \u001B[39m\u001B[32m2077\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minto_c\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmaybe_box_native\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   2078\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   2079\u001B[39m     \u001B[38;5;66;03m# Not an object dtype => all types will be the same so let the default\u001B[39;00m\n\u001B[32m   2080\u001B[39m     \u001B[38;5;66;03m# indexer return native python type\u001B[39;00m\n\u001B[32m   2081\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m into_c(\u001B[38;5;28mself\u001B[39m.items())\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:2077\u001B[39m, in \u001B[36m<genexpr>\u001B[39m\u001B[34m(.0)\u001B[39m\n\u001B[32m   2074\u001B[39m into_c = com.standardize_mapping(into)\n\u001B[32m   2076\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_object_dtype(\u001B[38;5;28mself\u001B[39m.dtype) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m.dtype, ExtensionDtype):\n\u001B[32m-> \u001B[39m\u001B[32m2077\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m into_c((k, maybe_box_native(v)) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.items())\n\u001B[32m   2078\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   2079\u001B[39m     \u001B[38;5;66;03m# Not an object dtype => all types will be the same so let the default\u001B[39;00m\n\u001B[32m   2080\u001B[39m     \u001B[38;5;66;03m# indexer return native python type\u001B[39;00m\n\u001B[32m   2081\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m into_c(\u001B[38;5;28mself\u001B[39m.items())\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 32
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
